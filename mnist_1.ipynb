{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deepmlblog.wordpress.com/2016/01/05/residual-networks-in-torch-mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "torch.manualSeed(1)\n",
    "\n",
    "function reload(name)\n",
    "    package.loaded[name] = nil\n",
    "    return require(name)\n",
    "end\n",
    "utils = reload('./utils')\n",
    "models = reload('./models')\n",
    "datasets = reload('./datasets')\n",
    "Logger = reload('./logger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data, train_label,\n",
    "    validation_data, validation_label = utils.load_data()\n",
    "\n",
    "train_data = train_data[{{1,1000}}]\n",
    "train_label = train_label[{{1, 1000}}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train\t\n",
       "-0.0078593129846774\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.99036449947161\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.42407388981865\t\n",
       "2.8215433152638\t\n",
       "validation\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.0048816247909239\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.99368015338313\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.42407388981865\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.8215433152638\t\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train')\n",
    "print(train_data:mean())\n",
    "print(train_data:std())\n",
    "print(train_data:min())\n",
    "print(train_data:max())\n",
    "print('validation')\n",
    "print(validation_data:mean())\n",
    "print(validation_data:std())\n",
    "print(validation_data:min())\n",
    "print(validation_data:max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "SEED = 1\n",
    "MODEL_NAME = 'mlp_3'\n",
    "TITLE = 'mnist_' .. MODEL_NAME\n",
    "-- VARIANT = 1\n",
    "-- LOGPATH = './results/' .. TITLE .. '/' .. VARIANT\n",
    "EPOCHS = 10\n",
    "\n",
    "p1 = {\n",
    "   learningRate = 1e-1,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p2 = {\n",
    "   learningRate = 1e-1,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0.2,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p3 = {\n",
    "   learningRate = 1e-2,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p4 = {\n",
    "   learningRate = 1e-2,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0.2,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p5 = {\n",
    "   learningRate = 1e-3,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p6 = {\n",
    "   learningRate = 1e-3,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0.2,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p7 = {\n",
    "   learningRate = 1e-4,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "p8 = {\n",
    "   learningRate = 1e-4,\n",
    "   learningRateDecay = 0,\n",
    "   weightDecay = 0.2,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "sgd_params = {p1, p2, p3, p4, p5, p6, p7, p8}\n",
    "\n",
    "batch_params = {\n",
    "    n_of_batches = 100\n",
    "}\n",
    "\n",
    "-- for i=1,1 do\n",
    "for i=1,#sgd_params do\n",
    "    VARIANT = i\n",
    "    LOGPATH = './results/' .. TITLE .. '/' .. VARIANT\n",
    "    start_training(sgd_params[i], batch_params)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "function start_training(sgd_params, batch_params)\n",
    "    \n",
    "    torch.manualSeed(SEED)\n",
    "    \n",
    "    local n_of_batches = batch_params.n_of_batches\n",
    "    \n",
    "    model = models[MODEL_NAME]()\n",
    "    criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "    x, dl_params = model:getParameters()\n",
    "\n",
    "    info_log = Logger(\n",
    "        LOGPATH, \n",
    "        {\n",
    "            general_info = {\n",
    "                title = TITLE,\n",
    "                description = '',\n",
    "                seed = SEED,\n",
    "                model = tostring(model),\n",
    "                criterion = tostring(criterion),\n",
    "            },\n",
    "            data_size = {\n",
    "                train_data = torch.totable(train_data:size()),\n",
    "                train_label = torch.totable(train_label:size()),\n",
    "                validation_data = torch.totable(validation_data:size()),\n",
    "                validation_label = torch.totable(validation_label:size()),\n",
    "            },\n",
    "            sgd_params = sgd_params\n",
    "        })\n",
    "    info_log:write()\n",
    "\n",
    "    logger = optim.Logger(LOGPATH .. '/accuracy.log')\n",
    "    logger:setNames{'train_loss', 'validation_loss'}\n",
    "\n",
    "    time_start = os.time()\n",
    "    \n",
    "    batch_size = train_data:size()[1] / n_of_batches\n",
    "    \n",
    "    for epoch=1,EPOCHS do\n",
    "        \n",
    "        assert(train_data:mean() > -0.1 and train_data:mean() < 0.1)\n",
    "        assert(validation_data:mean() > -0.1 and validation_data:mean() < 0.1)\n",
    "\n",
    "        train_loss = 0\n",
    "        \n",
    "        for j=1,n_of_batches do\n",
    "            batch_data = utils.get_batch(train_data, j, batch_size)\n",
    "            batch_label = utils.get_batch(train_label, j, batch_size)\n",
    "\n",
    "            sys.tic()\n",
    "            _, fs = optim.sgd(utils.feval,x,sgd_params)\n",
    "            duration = sys.toc()\n",
    "            train_loss = train_loss + fs[1]\n",
    "        end\n",
    "        \n",
    "        train_loss = train_loss/n_of_batches\n",
    "\n",
    "        validation_loss = calc_validation_loss(model, criterion, validation_data, validation_label)\n",
    "        logger:add{train_loss, validation_loss}\n",
    "\n",
    "    end\n",
    "\n",
    "    total_train_time = os.time() - time_start\n",
    "    \n",
    "    train_accuracy = utils.calc_accuracy(model, train_data, train_label)\n",
    "    validation_accuracy = utils.calc_accuracy(model, validation_data, validation_label)\n",
    "    \n",
    "    info_log:write_result({\n",
    "            model_name = MODEL_NAME,\n",
    "            variant = VARIANT,\n",
    "            epochs = EPOCHS,\n",
    "            learningRate = sgd_params.learningRate,\n",
    "            weightDecay = sgd_params.weightDecay,\n",
    "            total_train_time = total_train_time,\n",
    "            train_loss = train_loss,\n",
    "            validation_loss = validation_loss,\n",
    "            train_accuracy = train_accuracy,\n",
    "            validation_accuracy = validation_accuracy,\n",
    "        })\n",
    "--     info_log:write_result(\n",
    "--         total_train_time, train_loss, validation_loss, train_accuracy, validation_accuracy\n",
    "--     )\n",
    "\n",
    "    logger:style{'+-', '+-'}\n",
    "    logger:plot()\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.702\t\n",
       "validation_accuracy\t0.6501\t\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.88\t\n",
       "validation_accuracy\t0.8232\t\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- infos = json.load('./experiments/experiment_1/structures.json')\n",
    "-- -- print(infos[1])\n",
    "\n",
    "-- info = infos[1]\n",
    "\n",
    "function load_structure(info)\n",
    "\n",
    "    model_name = info.model\n",
    "    data_size = info.data_size\n",
    "    dataset_name = info.dataset\n",
    "    criterion_name = info.criterion\n",
    "    optim_name = info.optim\n",
    "\n",
    "    train_data, train_label, validation_data, validation_label =  datasets[dataset_name]()\n",
    "\n",
    "    if data_size ~= 0 then\n",
    "        train_data = train_data[{{1,data_size}}]\n",
    "        train_label = train_label[{{1,data_size}}]\n",
    "    end\n",
    "\n",
    "    model = models[model_name]()\n",
    "    criterion = nn[criterion_name]()\n",
    "    optimization = optim[optim_name]\n",
    "    dataset = {train_data, train_label, validation_data, validation_label}\n",
    "\n",
    "    return {\n",
    "        model = model,\n",
    "        criterion = criterion,\n",
    "        optimization = optimization,\n",
    "        dataset = dataset,\n",
    "    }\n",
    "\n",
    "end\n",
    "\n",
    "-- structure = load_from_infos(info)\n",
    "\n",
    "-- variants = json.load('./experiments/experiment_1/variants.json')\n",
    "-- variant = variants[1]\n",
    "\n",
    "function train(structure_json, variant)\n",
    "    \n",
    "    local structure = load_structure(structure_json)    \n",
    "    local model = structure.model\n",
    "    local criterion = structure.criterion\n",
    "    local optimization = structure.optimization\n",
    "    local dataset = structure.dataset\n",
    "    local train_data, train_label, validation_data, validation_label =\n",
    "        dataset[1], dataset[2], dataset[3], dataset[4]\n",
    "    \n",
    "    local sgd_params = variant.optim\n",
    "    local train_params = variant.train\n",
    "\n",
    "    torch.manualSeed(1)\n",
    "    local batch_size = train_params.batch_size\n",
    "    batch_size = batch_size == 0 and train_data:size()[1] or batch_size\n",
    "    local n_of_batches = train_data:size()[1] / batch_size\n",
    "\n",
    "    local epochs = 2\n",
    "    \n",
    "    logger = Logger(\n",
    "        './results_2/' .. 'experiment_1', --path\n",
    "        {'train_loss', 'validation_loss'}, -- log headers\n",
    "        {\n",
    "            structure = structure_json,\n",
    "            variant = variant,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    x, dl_params = model:getParameters()\n",
    "    local time_start = os.time()\n",
    "\n",
    "    for epoch=1,epochs do\n",
    "\n",
    "        local train_loss = 0\n",
    "        \n",
    "        for batch_number=1,n_of_batches do\n",
    "            batch_data = utils.get_batch(train_data, batch_number, batch_size)\n",
    "            batch_label = utils.get_batch(train_label, batch_number, batch_size)\n",
    "\n",
    "--             sys.tic()\n",
    "            _, fs = optimization(utils.feval,x,sgd_params)\n",
    "--             duration = sys.toc()\n",
    "            train_loss = train_loss + fs[1]\n",
    "\n",
    "        end\n",
    "                \n",
    "        train_loss = train_loss/n_of_batches\n",
    "        \n",
    "        local validation_loss = calc_validation_loss(model, criterion, validation_data, validation_label)\n",
    "\n",
    "        logger:append_log({train_loss, validation_loss})\n",
    "        \n",
    "        local train_accuracy = utils.calc_accuracy(model, train_data, train_label)\n",
    "        local validation_accuracy = utils.calc_accuracy(model, validation_data, validation_label)\n",
    "        local total_train_time = os.time() - time_start\n",
    "        \n",
    "        logger:write_results({\n",
    "                train_accuracy = train_accuracy,\n",
    "                validation_accuracy = validation_accuracy,\n",
    "                total_train_time = total_train_time,\n",
    "            })\n",
    "        \n",
    "        print('train_accuracy', train_accuracy)\n",
    "        print('validation_accuracy', validation_accuracy)\n",
    "\n",
    "    end\n",
    "end\n",
    "\n",
    "-- train(structure, variant)\n",
    "\n",
    "structures_json = json.load('./experiments/experiment_1/structures.json')\n",
    "variants_json = json.load('./experiments/experiment_1/variants.json')\n",
    "\n",
    "train(structures_json[1], variants_json[1])\n",
    "-- train(, './experiments/experiment_1/variants.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t2\t3\t4\t\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function start_training(sgd_params, batch_params)\n",
    "    \n",
    "    torch.manualSeed(SEED)\n",
    "    \n",
    "    local n_of_batches = batch_params.n_of_batches\n",
    "    \n",
    "    model = models[MODEL_NAME]()\n",
    "    criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "    x, dl_params = model:getParameters()\n",
    "\n",
    "    info_log = Logger(\n",
    "        LOGPATH,\n",
    "        {\n",
    "            general_info = {\n",
    "                title = TITLE,\n",
    "                description = '',\n",
    "                seed = SEED,\n",
    "                model = tostring(model),\n",
    "                criterion = tostring(criterion),\n",
    "            },\n",
    "            data_size = {\n",
    "                train_data = torch.totable(train_data:size()),\n",
    "                train_label = torch.totable(train_label:size()),\n",
    "                validation_data = torch.totable(validation_data:size()),\n",
    "                validation_label = torch.totable(validation_label:size()),\n",
    "            },\n",
    "            sgd_params = sgd_params\n",
    "        })\n",
    "    info_log:write()\n",
    "\n",
    "    logger = optim.Logger(LOGPATH .. '/accuracy.log')\n",
    "    logger:setNames{'train_loss', 'validation_loss'}\n",
    "\n",
    "    time_start = os.time()\n",
    "    \n",
    "    batch_size = train_data:size()[1] / n_of_batches\n",
    "    \n",
    "    for epoch=1,EPOCHS do\n",
    "        \n",
    "        assert(train_data:mean() > -0.1 and train_data:mean() < 0.1)\n",
    "        assert(validation_data:mean() > -0.1 and validation_data:mean() < 0.1)\n",
    "\n",
    "        train_loss = 0\n",
    "        \n",
    "        for j=1,n_of_batches do\n",
    "            batch_data = utils.get_batch(train_data, j, batch_size)\n",
    "            batch_label = utils.get_batch(train_label, j, batch_size)\n",
    "\n",
    "            sys.tic()\n",
    "            _, fs = optim.sgd(utils.feval,x,sgd_params)\n",
    "            duration = sys.toc()\n",
    "            train_loss = train_loss + fs[1]\n",
    "        end\n",
    "        \n",
    "        train_loss = train_loss/n_of_batches\n",
    "\n",
    "        validation_loss = calc_validation_loss(model, criterion, validation_data, validation_label)\n",
    "        logger:add{train_loss, validation_loss}\n",
    "\n",
    "    end\n",
    "\n",
    "    total_train_time = os.time() - time_start\n",
    "    \n",
    "    train_accuracy = utils.calc_accuracy(model, train_data, train_label)\n",
    "    validation_accuracy = utils.calc_accuracy(model, validation_data, validation_label)\n",
    "    \n",
    "    info_log:write_result({\n",
    "            model_name = MODEL_NAME,\n",
    "            variant = VARIANT,\n",
    "            epochs = EPOCHS,\n",
    "            learningRate = sgd_params.learningRate,\n",
    "            weightDecay = sgd_params.weightDecay,\n",
    "            total_train_time = total_train_time,\n",
    "            train_loss = train_loss,\n",
    "            validation_loss = validation_loss,\n",
    "            train_accuracy = train_accuracy,\n",
    "            validation_accuracy = validation_accuracy,\n",
    "        })\n",
    "--     info_log:write_result(\n",
    "--         total_train_time, train_loss, validation_loss, train_accuracy, validation_accuracy\n",
    "--     )\n",
    "\n",
    "    logger:style{'+-', '+-'}\n",
    "    logger:plot()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.702\t\n",
       "validation_accuracy\t0.6501\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.88\t\n",
       "validation_accuracy\t0.8232\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.906\t\n",
       "validation_accuracy\t0.8418\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.919\t\n",
       "validation_accuracy\t0.847\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.93\t\n",
       "validation_accuracy\t0.8515\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.938\t\n",
       "validation_accuracy\t0.8547\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.943\t\n",
       "validation_accuracy\t0.8588\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.949\t\n",
       "validation_accuracy\t0.8608\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.953\t\n",
       "validation_accuracy\t0.8628\t\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "train_accuracy\t0.958\t\n",
       "validation_accuracy\t0.8638\t\n",
       "\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofile('./run_experiment.lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4\t\n",
       "{eee=\"eee\",aaa=\"zzz\",zzz=\"zzz\",qqq=\"qqq\",d=\"ddd\",c=\"ccc\",b=\"bbb\",i=\"sdf\"}\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "require 'pl'\n",
    "\n",
    "tbl_1 = {\n",
    "    aaa = 'aaa',\n",
    "    b = 'bbb'\n",
    "}\n",
    "\n",
    "tbl_2 = {\n",
    "    c = 'ccc',\n",
    "    d = 'ddd'\n",
    "}\n",
    "\n",
    "tbl_3 = {\n",
    "    eee = 'eee',\n",
    "    zzz = 'zzz'\n",
    "}\n",
    "\n",
    "tbl_4 = {\n",
    "    qqq = 'qqq',\n",
    "    aaa = 'zzz'\n",
    "}\n",
    "\n",
    "function merge_tables(tables)\n",
    "  tbl = {}\n",
    "  for i=1,#tables do\n",
    "    tbl = tablex.merge(tbl, tables[i], true)\n",
    "  end\n",
    "  return tbl\n",
    "end\n",
    "\n",
    "res = merge_tables({tbl_1, tbl_2, tbl_3, tbl_4})\n",
    "-- res = tablex.merge(tbl_1, tbl_2, true)\n",
    "\n",
    "print(res)\n",
    "-- print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
